# Top_WRO-2025-documentation
# ğŸš— WRO 2025 Future Engineers - AI Autonomous Driving Project

This project is developed for the WRO 2025 Future Engineers competition. Based on Tensor Flow(machining learning). We use camera to gather data first,then give all the data to CNN neural network to generate/train a model,which will learn from the data,find the rule,and making its own prediction while running the car. We encoded the carâ€™s steering angle and throttle as continuous numerical outputs, enabling the neural network to learn the correlation between visual inputs and control signals. Then the car will generate the steering/throttle value based on the current image and the rule it found. The model outputs continuous control values for steering and throttle. These values are then interpreted by the control loop and converted into PWM signals via the PCA9685 driver, which in turn control the servo and motor to perform the actual driving actions.  
è¿™é‡Œæ”¾ä¸ªæ€»ä½“å›¾ç‰‡  


## ğŸ§± Hardware Components

1. **Raspberry Pi 4**  
Acts as the central computing unit, running the software stack, processing camera input, and executing the trained AI model in real time.  
ğŸ“· *(Insert photo here)*

2. **PCA9685**  
Converts numerical steering and throttle outputs into PWM signals, allowing precise control of the servo (for steering) and ESC (for throttle).  
ğŸ“· *(Insert photo here)*

3. **PiCamera**  
Captures real-time image frames from the carâ€™s perspective, which serve as input to the neural network for decision-making.  
ğŸ“· *(Insert photo here)*

4. **PS4 Controller**  
Used for manual control during data collection; allows the driver to steer and throttle the car while the system records input-output pairs.  
ğŸ“· *(Insert photo here)*

5. **Gyroscope**  
Gathers steering angle data to determine when the car should stop.  
For example, if you want the car to stop after completing 3 laps, you can write a program to halt it once the total steering angle equals 1080Â° (360Â° Ã— 3).  
ğŸ“· *(Insert photo here)*



## ğŸ’» Software & Code Structure

### ğŸ§  Software:
- **Raspberry Pi OS**  
  The operating system running on the Raspberry Pi. It is Linux-based and provides the runtime environment for our control scripts and model execution.

- **TensorFlow**  
  A deep learning library used to train and load neural network models for autonomous driving.

- **Neural network model (.h5 file)**  
  The trained model file that stores driving strategies, used during inference to generate control outputs.

### ğŸ Python Code:
- [`manage.py`](manage.py)  
  The main entry file of the project, start training or run the car
  
- [`train.py`](train.py) 
  Trains the CNN model based on labeled image-throttle-steering data.

- [`main_freerun.py`](main_freerun.py)
  Runs the trained model on the vehicle in real time for autonomous driving.

- [`_Control_RCcar_with_KB.py`](_Control_RCcar_with_KB.py)
  A manual control script to test if the car's motors and steering servo respond correctly to PWM signals via keyboard input.

  
## The Overall Training Pipeline
è¿™ä¸€éƒ¨åˆ†æ˜¯ä»‹ç»æˆ‘ä»¬è®­ç»ƒçš„å¤§ä½“æµç¨‹ï¼šè·¯ç”±å™¨/è½¦å­å¼€æœºã€é“¾æ¥æ‰‹æŸ„ã€æµ‹è¯•è½¦å­æ€§èƒ½ã€ç»ˆç«¯å‘½ä»¤å¼€å§‹æ”¶é›†æ•°æ®ã€filezellaä¼ æ•°æ®åˆ°è‡ªå·±ç”µè„‘ã€è®­ç»ƒã€è¿”å›æ¨¡å‹ã€‚

## ğŸŸ¢ Free Run: Implementation and Challenges We Overcame
è¿™éƒ¨åˆ†ä»‹ç»æˆ‘ä»¬freerunçš„è®­ç»ƒ ä¸»è¦ä¸‰ç‚¹ï¼š1.å¤šæ¬¡å˜æ¢åœºåœ° è¾¾åˆ°è®©è½¦å­ä¸ä¾èµ–å•ä¸€ç¯å¢ƒçš„æ•ˆæœ 2.æ•…æ„è¾“å…¥æç«¯æƒ…å†µ ç»™è½¦æœ‰æ­£å€¼çš„è¾“å…¥è®©ä»–å­¦ä¼šåº”å¯¹ 3.ç”¨é™€èºä»ªå®ç°åœæ­¢ç¨‹åºã€‚

## Obstacle Run:ä¸€ä¸ªå‰¯æ ‡é¢˜ è¿˜æ²¡æƒ³å¥½
ä¸»è¦å†…å®¹å°±æ˜¯è¯´æˆ‘ä»¬å¦‚ä½•è®­ç»ƒéšœç¢è·‘ æ¯”å¦‚ä¹Ÿæ˜¯å¤šæ¬¡éšæœºæ¢æŸ±å­ æ‘†å¥½åœè½¦åŒº æ•…æ„åœ¨æŸ±å­å‰æ”¾æ…¢è½¬å¼¯ç­‰

## ğŸ…¿ï¸ Training the Stop Model: Difficulties We Faced and How We Solved Them
è¿™éƒ¨åˆ†å†™åœè½¦ å¯ä»¥å…ˆç©ºç€ å› ä¸ºè¿˜æ²¡åš

## ğŸ”š Conclusion & Future Work
æ€»ç»“å’Œå±•æœ› æ€»ç»“æ®µè½


